===============================================================================
Installation Setup
===============================================================================

- Install lubuntu desktop on masters

- Flash cubieboards with lubuntu server
 - Post-install:
 # passwd root
 # apt-get update
 # apt-get install python-apt  
 # export LANG=C

- Setup /etc/hostname and /etc/hosts file
 - Setup static IPs on router

- Create, mount and expand /data on slave cubieboards microSD
  # mkdir /data
  # mount /dev/mmcblk0p1 /data
  # df -TH
  - Add "/dev/mmcblk0p1 /data ext4 defaults,noatime 0 2" to /etc/fstab

- Expand cubieboard root dir from 2GB to 4GB
  # ./nand-part /dev/nand "env 32768" "boot 65536" "rootfs 7536640" "swap 0"
  # reboot
  # resize2fs -f /dev/nandd

- Run the master-setup.sh or slave-setup.sh
  - Performs directory and permission setup
  - After running script copy over applicable user bash-profiles

- Setup SSH for hadoop user. Make sure hadoop user can ssh from master 
  to all slaves

  # ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
  # cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
  # ssh localhost
  
- Disable IPv6 on all systems:

  Edit /etc/sysctl.conf and add: 

#disable ipv6
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv6.conf.lo.disable_ipv6 = 1

  Reboot
  Verify: cat /proc/sys/net/ipv6/conf/all/disable_ipv6
  “1″ means IPv6 has been disabled
  

- Copy over Java, Hadoop and the Hadoop configs to the master to /root/sw
  - Copy from the master to all the slaves to /root/sw

- Install Java in /usr/lib/jvm on the master and slaves

- Install Hadoop in /opt/hadoop on the master and slaves
  - Install the Hadoop configs

- Install syslog-ng

===============================================================================
Post-Installation Checklist
===============================================================================

Cubieboards:
============
- SSH to cubieboard as root from dev box

[root@cubieboard2-1 ~]$ cat .bash_profile 
#!/bin/bash

export LANG=C
export PS1="\e[1;31m[\u@\h \W]$ \e[m"

[root@cubieboard2-1 ~]$ df -Th
Filesystem     Type   Size  Used Avail Use% Mounted on
/dev/nandd     ext4   3.6G  1.3G  2.2G  38% /
none           tmpfs  4.0K     0  4.0K   0% /sys/fs/cgroup
none           tmpfs   91M  196K   91M   1% /run
none           tmpfs  5.0M     0  5.0M   0% /run/lock
none           tmpfs  454M     0  454M   0% /run/shm
none           tmpfs  100M     0  100M   0% /run/user
/dev/mmcblk0p5 ext4    55G   17M   52G   1% /data
[root@cubieboard2-1 ~]$ ls -l /data
total 4
drwxr-xr-x 2 hadoop hadoop 2048 Oct 25 15:05 hadoop
drwx------ 2 root   root   2048 Oct 20 22:24 lost+found
[root@cubieboard2-1 ~]$ ls -l /opt
total 8
lrwxrwxrwx  1 root   root     12 Oct 21 06:01 hadoop -> hadoop-1.2.1
drwxr-xr-x 15 hadoop hadoop 4096 Jul 22 22:26 hadoop-1.2.1
[root@cubieboard2-1 ~]$ ls -la /var/opt/hadoop/
total 12
drwxr-xr-x 3 hadoop hadoop 4096 Oct 25 15:02 .
drwxr-xr-x 3 root   root   4096 Oct 25 15:02 ..
drwxr-xr-x 2 hadoop hadoop 4096 Oct 25 15:02 pids
[root@cubieboard2-1 ~]$ ls -la /var/log/hadoop
total 8
drwxr-xr-x  2 hadoop hadoop 4096 Oct 25 15:02 .
drwxr-xr-x 10 root   root   4096 Oct 25 15:02 ..
[root@cubieboard2-1 ~]$ 

- Switch user to linaro and verify:

[linaro@cubieboard2-1 ~]$ cat .bash_profile 
#!/bin/bash

export LANG=C
export PS1="\e[1;36m[\u@\h \W]$ \e[m"

export JAVA_HOME=/usr/lib/jvm/java-7-oracle

export PATH=$PATH:$JAVA_HOME/bin

[linaro@cubieboard2-1 ~]$ pwd
/home/linaro

- Switch user to hadoop and verify:

[linaro@cubieboard2-1 ~]$ logout
[root@cubieboard2-1 ~]$ su - hadoop
[hadoop@cubieboard2-1 ~]$ cat .bash_profile 
#!/bin/bash

export LANG=C
export PS1="\e[1;33m[\u@\h \W]$ \e[m"

export JAVA_HOME=/usr/lib/jvm/java-7-oracle

export HADOOP_PREFIX=/opt/hadoop
export HADOOP_HOME=/opt/hadoop
export HADOOP_INSTALL=/opt/hadoop

export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_PREFIX/bin

[hadoop@cubieboard2-1 ~]$ pwd
/home/hadoop

- Repeat for each slave in the cluster

# df -Th
# cat .bash_profile
# ls -l /data
# ls -l /opt
# ls -la /var/opt/hadoop
# ls -la /var/log/hadoop
# pwd
# su - linaro 
# cat .bash_profile
# pwd
# java -version
# logout
# su - hadoop
# cat .bash_profile
# pwd
# java -version
# which hadoop
# logout

